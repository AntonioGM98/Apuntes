{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b1bc26",
   "metadata": {},
   "source": [
    "# Modelo bolsa de palabras para sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de043dec",
   "metadata": {},
   "source": [
    "## Planteamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c205ad",
   "metadata": {},
   "source": [
    "Una técnica popular para desarrollar modelos de análisis de sentimientos es utilizar un modelo de bolsa de palabras que transforma los documentos en vectores donde a cada palabra del documento se le asigna una puntuación. Vamos a ver cómo:\n",
    " - Preparar los datos del texto para modelar un vocabulario restringido.\n",
    " - Utilizar el modelo de bolsa de palabra para preparar datos train/test.\n",
    " - Desarrollar un modelo de bolsa de palabras de perceptrón multicapa.\n",
    " \n",
    "Entonces, vamos a dividirlo en los siguientes apartados:\n",
    " 1. Conjunto de datos de reseñas de películas\n",
    " 2. Preparación de datos\n",
    " 3. Representación de bolsa de palabras\n",
    " 4. Modelos de aprendizaje\n",
    " 5. Comparación de métodos de puntuación de palabras\n",
    " 6. Predicción en nuevas reseñas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224020b1",
   "metadata": {},
   "source": [
    "# 1. Conjunto de datos de reseñas de películas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e114b676",
   "metadata": {},
   "source": [
    "Vamos a seguir utilizando el mismo dataset que en la parte anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb24c2a9",
   "metadata": {},
   "source": [
    "# 2. Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376f168",
   "metadata": {},
   "source": [
    "Como tenemos en cuenta la limpieza anterior nos vamos a centrar en:\n",
    " - División en train/test\n",
    " - Cargar y limpiar los datos para eliminar puntuación y números\n",
    " - Definir un vocabulario de palabras preferidas\n",
    " \n",
    "Vamos a decidir si una reseña dada por un usuario es buena o mala en función del texto que ponga. Esto quiere decir que para nuevos datos no etiquetados hay que realizar el mismo preprocesamiento de datos que en el conjunto de entrenamiento.\n",
    "\n",
    "Haremos una división 90/10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376fd3d",
   "metadata": {},
   "source": [
    "## 2.1 Carga y limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64c1de",
   "metadata": {},
   "source": [
    "Ya hemos observado que el texto está bastante limpio, por lo que no requiere mucha preparación. Entonces, vamos a realizar el siguiente preprocesamiento:\n",
    "  - Dividir tokens en espacios en blanco\n",
    "  - Eliminar toda puntuación de las palabras\n",
    "  - Eliminar todas las palabras que no estén compuestas únicamente por caracteres alfanuméricos\n",
    "  - Eliminar todas las palabras conocidas vacías\n",
    "  - Eliminar las palabras cuya longitud sea $\\leq$ 1\n",
    "  \n",
    "Para esto reutilizamos las funciones anteriores:\n",
    "  - `load_doc()`, carga un documento desde un fichero listo para utilizar con la función `clean_doc()`\n",
    "  - `clean_doc()`, recibe por parámetro un texto sin procesar y devuelve una lista de tokens limpios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605aaf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcbf441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "def clean_doc(text):\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Eliminamos puntuación\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    re_punc = [re_punc.sub('', w) for w in tokens]\n",
    "    \n",
    "    # Eliminamos números\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Eliminamos las stop words\n",
    "    stop_words = set(stopwords.words('English'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    \n",
    "    tokens = [w for w in tokens if len(w) > 1]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbdc74",
   "metadata": {},
   "source": [
    "## 2.2 Definir un vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b3a65",
   "metadata": {},
   "source": [
    "Es importante limitar las palabras a aquellas que se crea que tenga poder predictivo.\n",
    "\n",
    "Para esto vamos a reutilizar las funciones vistas. Primero, desarrollamos un vocabulario a modo de `Counter` y cada fragmento se puede agregar al contador y podemos cargar todas las reviews en un fichero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e45f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def add_doc_to_vocab(filename, vocab):\n",
    "    doc = load_doc(filename)\n",
    "    tokens = clean_doc(doc)\n",
    "    vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c34cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(directory, vocab):\n",
    "    for filename in listdir(directory):\n",
    "        if not filename.endswith('.txt'):\n",
    "            continue\n",
    "    \n",
    "        path = directory + filename\n",
    "        add_doc_to_vocab(path, \n",
    "                         vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98b26b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37589\n",
      "[('film', 8849), ('one', 5514), ('movie', 5429), ('like', 3543), ('even', 2554), ('good', 2313), ('time', 2280), ('story', 2110), ('would', 2041), ('much', 2022), ('also', 1965), ('get', 1920), ('character', 1902), ('two', 1824), ('characters', 1813), ('first', 1766), ('see', 1726), ('way', 1668), ('well', 1654), ('make', 1590), ('really', 1556), ('films', 1513), ('little', 1487), ('life', 1467), ('plot', 1448), ('people', 1418), ('could', 1395), ('bad', 1372), ('scene', 1372), ('never', 1360), ('best', 1298), ('new', 1275), ('many', 1267), ('scenes', 1262), ('man', 1255), ('know', 1207), ('movies', 1180), ('great', 1138), ('another', 1111), ('love', 1087), ('go', 1073), ('action', 1073), ('us', 1065), ('director', 1054), ('something', 1047), ('end', 1044), ('still', 1037), ('seems', 1032), ('back', 1031), ('made', 1025)]\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "pos_path = 'Data/review polarity/pos/'\n",
    "neg_path = 'Data/review polarity/neg/'\n",
    "\n",
    "process_docs(pos_path, vocab)\n",
    "process_docs(neg_path, vocab)\n",
    "\n",
    "print(len(vocab))\n",
    "\n",
    "print(vocab.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f809975",
   "metadata": {},
   "source": [
    "Ahora vamos a eliminar todas las palabras que tengan menos de 2 ocurrencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e8e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24392\n"
     ]
    }
   ],
   "source": [
    "umbral = 2\n",
    "tokens = [k for k,c in vocab.items() if c>=umbral]\n",
    "\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3839b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename,\n",
    "                'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ec3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = 'vocab.txt'\n",
    "\n",
    "save_list(tokens, vocab_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e024d3",
   "metadata": {},
   "source": [
    "# 3. Representación de la bolsa de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17177b52",
   "metadata": {},
   "source": [
    "Aspectos a tener en cuenta:\n",
    "  - Cada documento se convierte en una representación vectorial.\n",
    "  - El número de elementos en el vector que representa un documento corresponde al número de palabras en el vocabulario.\n",
    "  - Cuanto mayor sea el vocabulario, mayor será la representación del vector, de ahí la preferencia por tener vocabularios más reducidos.\n",
    "\n",
    "Ahora, vamos a convertir las reviews en vectores preparados para entrenar un modelo inicial de red neuronal, es decir:\n",
    "  1. Convertir reseñas en tokens\n",
    "  2. Codificarlas con una representación de modelo de bolsa de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c486b",
   "metadata": {},
   "source": [
    "## 3.1 Reviews a líneas de tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e7179",
   "metadata": {},
   "source": [
    "Lo primero es realizar la limpieza de los documentos. Para ello, creamos la función `doc_to_line()` que cargará el documento, lo limpiará, filtrará los tokens que no están en el vocabulario y devolverá el documento como una cadena de tokens separados por espacios en blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217c6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_line(filename, vocab):\n",
    "    doc = load_doc(filename)\n",
    "    tokens = clean_doc(doc)\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c600e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(directory, vocab):\n",
    "    lines = list()\n",
    " \n",
    "    for filename in listdir(directory):\n",
    "        if filename.startswith('cv9'):\n",
    "            continue\n",
    "        \n",
    "        path = directory + filename\n",
    "        line = doc_to_line(path, vocab)\n",
    "        lines.append(line)\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa03d00",
   "metadata": {},
   "source": [
    "Ahora vamos a crear una función `clean_load_dataset()` que llamará a `process_docs()` para construir el dataset en el que las revisiones positivas son 1 y las negativas 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62568738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_dataset(vocab):\n",
    "    neg = process_docs('Data/review polarity/neg/', \n",
    "                       vocab)\n",
    "    pos = process_docs('Data/review polarity/pos/', \n",
    "                       vocab)\n",
    "    \n",
    "    docs = neg + pos \n",
    "    \n",
    "    labels = [0 for _ in range(len(neg))] + [1 for _ in range(len(pos))]\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb3cac",
   "metadata": {},
   "source": [
    "Finalmente, tenemos que cargar el vocabulario y convertirlo en un conjunto para utilizar en revisiones de limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff87b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = load_doc(vocab_path)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ba9baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, labels = load_clean_dataset(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570b4e2",
   "metadata": {},
   "source": [
    "## 3.2 Reviews de películas a vectores de bolsa de palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6597e95e",
   "metadata": {},
   "source": [
    "La clase `Tokenizer` es conveniente y transformará fácilmente los documentos en vectores codificados. Primero, se debe crear el `Tokenizer` y, luego, realizar el `fit`.\n",
    "\n",
    "En este caso, se trata de la agregación de matrices positive_lines y negative_lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "864a02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    \n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c0885",
   "metadata": {},
   "source": [
    "Los documentos se pueden codificar mediante `Tokenizer` con la función `texts_to_matrix()`, que tiene 2 parámetros:\n",
    "  - Lista de documentos para codificar\n",
    "  - Modo de codificación\n",
    "      · Aquí específicamos `freq` para puntuar palabras en función de su frecuencia en el momento\n",
    "      \n",
    "Vamos a tener que modificar la función `process_docs()` para procesar de forma selectiva las reviews en train_test.\n",
    "  - Admitimos la carga de train/test agregando un argumento `is_train` y usándolo para decidir qué nombres de archivos omitir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "031c81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(directory, vocab, is_train):\n",
    "    lines = list()\n",
    " \n",
    "    for filename in listdir(directory):\n",
    "        if is_train and filename.startswith('cv9'):\n",
    "            continue\n",
    "        \n",
    "        if not is_train and not filename.startswith('cv9'):\n",
    "            continue\n",
    "        \n",
    "        path = directory + filename\n",
    "        line = doc_to_line(path, vocab)\n",
    "        lines.append(line)\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67736d48",
   "metadata": {},
   "source": [
    "Igualmente, vamos a tener que modificar la función `load_clean_dataset()` para cargar el train o test y asegurar que devuelva una matriz NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ffe3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_dataset(vocab, is_train):\n",
    "    neg = process_docs('Data/review polarity/neg/', \n",
    "                       vocab,\n",
    "                       is_train)\n",
    "    \n",
    "    pos = process_docs('Data/review polarity/pos/', \n",
    "                       vocab,\n",
    "                       is_train)\n",
    "    \n",
    "    docs = neg + pos \n",
    "    \n",
    "    labels = [0 for _ in range(len(neg))] + [1 for _ in range(len(pos))]\n",
    "    return docs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e46a65",
   "metadata": {},
   "source": [
    "Ahora vamos a cargar todas las reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a15c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 24208) (200, 24208)\n"
     ]
    }
   ],
   "source": [
    "train_docs, y_train = load_clean_dataset(vocab, \n",
    "                                         True)\n",
    "test_docs, y_test = load_clean_dataset(vocab, \n",
    "                                       False)\n",
    "\n",
    "tokenizer = create_tokenizer(train_docs)\n",
    "\n",
    "x_train = tokenizer.texts_to_matrix(train_docs,\n",
    "                                   mode='freq')\n",
    "\n",
    "x_test = tokenizer.texts_to_matrix(test_docs,\n",
    "                                  mode='freq')\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b47b5",
   "metadata": {},
   "source": [
    "Vemos que train y test tienen 1800 y 200 documentos, respectivamente, y cada uno con igual tamaño de vocabulario de codificación, es decir, 24208."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff4970",
   "metadata": {},
   "source": [
    "# 4. Modelos de análsis de reseñas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de35132f",
   "metadata": {},
   "source": [
    "Vamos a implementar un modelo perceptrón multicapa para clasificar documentos codificados como positivos o negativos. Vamos a tener 3 partes:\n",
    "  1. Primer modelo de análisis de reseña\n",
    "  2. Comparación de los modos de puntuación de palabras\n",
    "  3. Predicción para nuevas reseñas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d3d86",
   "metadata": {},
   "source": [
    "## 4.1 Modelo de análisis de primera opinión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2b73c",
   "metadata": {},
   "source": [
    "El modelo tendrá:\n",
    "  - Una capa de entrada igual al número de palabras del vocabulario y, a su vez, la longitud de los documentos de entrada\n",
    "  - Una sola capa oculta de 50 neuronas con función de activación ReLu\n",
    "  - La capa de salida consta de una única neurona con función de activación sigmoidea\n",
    "  - Optimizador ADAM\n",
    "  - Función de pérdida `binary_crossentropy`\n",
    "  - Evaluaremos accuracy al entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31e5c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "\n",
    "def base_model(n_words):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50,\n",
    "                   input_shape=(n_words, ),\n",
    "                   activation='relu'\n",
    "                   ))\n",
    "    model.add(Dense(1,\n",
    "                    activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    plot_model(model,\n",
    "               to_file='model.png',\n",
    "               show_shapes=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27b4fcfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "57/57 - 1s - loss: 0.6917 - accuracy: 0.5389 - 754ms/epoch - 13ms/step\n",
      "Epoch 2/10\n",
      "57/57 - 0s - loss: 0.6824 - accuracy: 0.8517 - 373ms/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "57/57 - 0s - loss: 0.6633 - accuracy: 0.8678 - 367ms/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "57/57 - 0s - loss: 0.6327 - accuracy: 0.8550 - 366ms/epoch - 6ms/step\n",
      "Epoch 5/10\n",
      "57/57 - 0s - loss: 0.5930 - accuracy: 0.9300 - 376ms/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "57/57 - 0s - loss: 0.5473 - accuracy: 0.9444 - 370ms/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "57/57 - 0s - loss: 0.4998 - accuracy: 0.9500 - 366ms/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "57/57 - 0s - loss: 0.4540 - accuracy: 0.9500 - 371ms/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "57/57 - 0s - loss: 0.4096 - accuracy: 0.9594 - 372ms/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "57/57 - 0s - loss: 0.3670 - accuracy: 0.9656 - 369ms/epoch - 6ms/step\n",
      "Accuracy en test: 85.50%\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "n_words = x_test.shape[1]\n",
    "y_train = array(y_train)\n",
    "y_test = array(y_test)\n",
    "\n",
    "model = base_model(n_words)\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          verbose=2)\n",
    "\n",
    "loss, acc = model.evaluate(x_test,\n",
    "                           y_test,\n",
    "                           verbose=0)\n",
    "\n",
    "print('Accuracy en test: {:.2%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa53db4",
   "metadata": {},
   "source": [
    "Resumen del modelo:\n",
    "\n",
    "![](model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f09783",
   "metadata": {},
   "source": [
    "Vemos que:\n",
    "  - El modelo se ajusta fácilmente a los datos de entrenamiento dentro de las 10 épocas, logrando un accuracy cerano al 100%\n",
    "  - La evaluación es también es buena, logrando un accuracy superior al 87%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313ff36",
   "metadata": {},
   "source": [
    "## 5 Comparación de métodos de puntuación de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33789c34",
   "metadata": {},
   "source": [
    "La función `texts_to_matrix()` proporciona 4 métodos diferentes para puntuar palabras, que son:\n",
    "  - `binary`: Donde las palabras se marcan como presentes (1) o ausentes(0)\n",
    "  - `count`: Donde el recuento de ocurrencias de cada palabra se marcan como un número entero\n",
    "  - `tfidf`: Cada palabra se puntúa en función de su frecuencia, donde se penalizan las palabras comunes en todos los documentos\n",
    "  - `freq`: Las palabras se puntuán en función de su frecuencia de aparición en el documento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd751745",
   "metadata": {},
   "source": [
    "Vamos a crear la función `prepare_data()`, que lo utilizaremos para crear los conjuntos train/test al llamarlo, en lugar de hacerlo manual, y indicando el modo en la función `texts_to_matrix()` en función de un parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4757ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_docs, test_docs, mode):\n",
    "    tokenizer = create_tokenizer(train_docs)\n",
    "    \n",
    "    x_train = tokenizer.texts_to_matrix(train_docs,\n",
    "                                        mode=mode)\n",
    "    x_test = tokenizer.texts_to_matrix(test_docs,\n",
    "                                       mode=mode)\n",
    "    \n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11209b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(xtrain, ytrain, xtest, ytest):\n",
    "    scores = list()\n",
    "    iterations = 10\n",
    "    n_words = xtest.shape[1]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        model = base_model(n_words)\n",
    "        model.fit(xtrain,\n",
    "                  ytrain,\n",
    "                  epochs=10,\n",
    "                  verbose=0)\n",
    "        _, acc = model.evaluate(xtest,\n",
    "                                ytest,\n",
    "                                verbose=0)\n",
    "        scores.append(acc)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8dd0b71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 50)                1210450   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_32 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_38 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_52 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_56 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_58 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_62 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_64 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_68 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " dense_70 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_74 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_76 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_80 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot\n",
    "\n",
    "train_docs, y_train = load_clean_dataset(vocab, \n",
    "                                         True)\n",
    "test_docs, y_test = load_clean_dataset(vocab, \n",
    "                                       False)\n",
    "y_train = array(y_train)\n",
    "y_test = array(y_test)\n",
    "\n",
    "modes = ['binary', 'count', 'tfidf', 'freq']\n",
    "\n",
    "results = DataFrame()\n",
    "\n",
    "for mode in modes:\n",
    "    x_train, x_test = prepare_data(train_docs,\n",
    "                                   test_docs,\n",
    "                                   mode)\n",
    "    results[mode] = evaluate_model(x_train,\n",
    "                                   y_train,\n",
    "                                   x_test,\n",
    "                                   y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4860e3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          binary      count      tfidf       freq\n",
      "count  10.000000  10.000000  10.000000  10.000000\n",
      "mean    0.920500   0.894000   0.869500   0.872000\n",
      "std     0.004972   0.008097   0.011655   0.016865\n",
      "min     0.915000   0.885000   0.850000   0.840000\n",
      "25%     0.916250   0.890000   0.865000   0.860000\n",
      "50%     0.920000   0.892500   0.870000   0.880000\n",
      "75%     0.923750   0.895000   0.877500   0.885000\n",
      "max     0.930000   0.910000   0.885000   0.890000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results.describe())\n",
    "\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bea759",
   "metadata": {},
   "source": [
    "Como vemos, la puntuación media de `count` y `binary` parece ser mejor que `tfidf` y `freq`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72bf38",
   "metadata": {},
   "source": [
    "## 6 Predicción de datos no etiquetados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754a8f88",
   "metadata": {},
   "source": [
    "Por último, podemos desarrollar y utilizar un modelo final para hacer predicciones para nuevas reviews no etiquetadas.\n",
    "  - Primero, entrenamos un modelo final con todos lo datos disponibles.\n",
    "  - Utilizaremos el modo binario para calificar el modelo.\n",
    "  \n",
    "Podemos hacer una predicción de un valor de clase directamente con el modelo de ajuste llamando a `predict()` que devolverá un entero de 0 para una review negativa y 1 para una positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5485a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review, vocab, tokenizer, model):\n",
    "    tokens = clean_doc(review)\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    line = ' '.join(tokens)\n",
    "    \n",
    "    encoded = tokenizer.texts_to_matrix([line],\n",
    "                                       mode='binary')\n",
    "    yhat = model.predict(encoded,\n",
    "                         verbose=0)\n",
    "    percentage_pos = yhat[0,0]\n",
    "    \n",
    "    if round(percentage_pos) == 0:\n",
    "        return (1-percentage_pos), 'Negativa'\n",
    "    \n",
    "    return percentage_pos, 'Positiva'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed6cdb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_84 (Dense)            (None, 50)                1210450   \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1210501 (4.62 MB)\n",
      "Trainable params: 1210501 (4.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_docs, y_train = load_clean_dataset(vocab, \n",
    "                                         True)\n",
    "test_docs, y_test = load_clean_dataset(vocab, \n",
    "                                       False)\n",
    "y_train = array(y_train)\n",
    "y_test = array(y_test)\n",
    "\n",
    "x_train, x_test = prepare_data(train_docs,\n",
    "                               test_docs,\n",
    "                               mode='binary')\n",
    "\n",
    "n_words = x_test.shape[1]\n",
    "\n",
    "model = base_model(n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe6048",
   "metadata": {},
   "source": [
    "Realizamos el fit del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3873c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 - 0s - loss: 0.0590 - accuracy: 0.9950 - 367ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "57/57 - 0s - loss: 0.0171 - accuracy: 1.0000 - 376ms/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "57/57 - 0s - loss: 0.0083 - accuracy: 1.0000 - 409ms/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "57/57 - 0s - loss: 0.0047 - accuracy: 1.0000 - 390ms/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "57/57 - 0s - loss: 0.0030 - accuracy: 1.0000 - 391ms/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "57/57 - 0s - loss: 0.0020 - accuracy: 1.0000 - 400ms/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "57/57 - 0s - loss: 0.0014 - accuracy: 1.0000 - 400ms/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "57/57 - 0s - loss: 0.0011 - accuracy: 1.0000 - 408ms/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "57/57 - 0s - loss: 8.5388e-04 - accuracy: 1.0000 - 407ms/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "57/57 - 0s - loss: 6.8827e-04 - accuracy: 1.0000 - 409ms/epoch - 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b590a2b1f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c5403",
   "metadata": {},
   "source": [
    "Vamos a crear alguna reseña nosotros de prueba para verificar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4de7c9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review: [Steeped in enigmatic allure,the film seamlessly weaves a tapestry of emotions, leaving the audience with a delightful ambiguity that sparks contemplation. The narrative dances gracefully between light and shadow, inviting viewers to traverse the intricate maze of the human experience. The characters, shrouded in a captivating mystique, resonate with a nuanced authenticity that lingers in the mind long after the credits roll. A cinematic enigma that beckons you to explore its depths, this film is a mesmerizing journey into the sublime, where every frame is a brushstroke on the canvas of cinematic brilliance]\n",
      "Sentiment: Positiva (86.958%)\n",
      "\n",
      "Review: [In the realm of cinema, this film stands as a perplexing misstep, stumbling through a narrative that feels disjointed and uninspired. From the outset, the plot meanders aimlessly, failing to engage the audience with any semblance of coherence. Characters, poorly developed and devoid of relatability, drift through scenes like mere placeholders in a forgettable storyline. The dialogue, instead of providing depth, often descends into banality, leaving viewers yearning for substance. The cinematography, rather than elevating the viewing experience, feels mundane and lacks the visual poetry that could have breathed life into this lackluster production. Despite a potentially intriguing premise, the film ultimately collapses under the weight of its own mediocrity, leaving behind a trail of unfulfilled potential and viewer disappointment.]\n",
      "Sentiment: Negativa (88.226%)\n"
     ]
    }
   ],
   "source": [
    "text_pos = 'Steeped in enigmatic allure,the film seamlessly weaves a tapestry of emotions, leaving the audience with a delightful ambiguity that sparks contemplation. The narrative dances gracefully between light and shadow, inviting viewers to traverse the intricate maze of the human experience. The characters, shrouded in a captivating mystique, resonate with a nuanced authenticity that lingers in the mind long after the credits roll. A cinematic enigma that beckons you to explore its depths, this film is a mesmerizing journey into the sublime, where every frame is a brushstroke on the canvas of cinematic brilliance'\n",
    "percentage, sentiment = predict_sentiment(text_pos,\n",
    "                                          vocab,\n",
    "                                          tokenizer,\n",
    "                                          model)\n",
    "print()\n",
    "print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text_pos, sentiment, percentage*100))\n",
    "\n",
    "text_neg = 'In the realm of cinema, this film stands as a perplexing misstep, stumbling through a narrative that feels disjointed and uninspired. From the outset, the plot meanders aimlessly, failing to engage the audience with any semblance of coherence. Characters, poorly developed and devoid of relatability, drift through scenes like mere placeholders in a forgettable storyline. The dialogue, instead of providing depth, often descends into banality, leaving viewers yearning for substance. The cinematography, rather than elevating the viewing experience, feels mundane and lacks the visual poetry that could have breathed life into this lackluster production. Despite a potentially intriguing premise, the film ultimately collapses under the weight of its own mediocrity, leaving behind a trail of unfulfilled potential and viewer disappointment.'\n",
    "\n",
    "print()\n",
    "\n",
    "percentage, sentiment = predict_sentiment(text_neg,\n",
    "                                          vocab,\n",
    "                                          tokenizer,\n",
    "                                          model)\n",
    "print('Review: [%s]\\nSentiment: %s (%.3f%%)' % (text_neg, sentiment, percentage*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
